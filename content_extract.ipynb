{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d88c590b-69fa-4881-9da2-2faf0f00b1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q google-cloud-documentai\n",
    "!pip install -q PyMuPDF\n",
    "!pip install -q google-cloud-storage\n",
    "!pip show -q google-cloud-documentai\n",
    "!pip install -q --upgrade google-cloud-documentai\n",
    "!pip install -q opencv-python\n",
    "!pip install -q pdf2image\n",
    "!pip install aspose-words -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24a29c4f-355d-4230-8e00-c85959dc0a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from typing import Optional\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai\n",
    "import aspose.words as aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9aad937-1708-43fa-b0f6-0baae0ac6762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_extraction(document):\n",
    "    extracted_data = {\"last_name\": [], \"first_name\": [], \"rank\": [], \"regiment\": [], \"page\": []}\n",
    "\n",
    "    # Iterate through each line of the document\n",
    "    for line in document.text.split(\"\\n\"):\n",
    "        \n",
    "        entities_from_line = {\"last_name\": None, \"first_name\": None, \"rank\": None, \"regiment\": None, \"page\": None}\n",
    "\n",
    "        # Iterate through each entity in the document\n",
    "        for entity in document.entities:\n",
    "            if entity.type_ in entities_from_line:\n",
    "                # Check if the entity is in the current line\n",
    "                if entity.mention_text in line:\n",
    "                    entities_from_line[entity.type_] = entity.mention_text\n",
    "\n",
    "        # Append entities from the line to extracted_data\n",
    "        for entity_type, entity_value in entities_from_line.items():\n",
    "            extracted_data[entity_type].append(entity_value)\n",
    "\n",
    "    # Find the length of the longest list among all entities\n",
    "    max_length = max(len(value_list) for value_list in extracted_data.values())\n",
    "\n",
    "    # Pad all lists to have the same length\n",
    "    for key, value_list in extracted_data.items():\n",
    "        while len(value_list) < max_length:\n",
    "            value_list.append(None)\n",
    "    \n",
    "    # Check for null values in the \"rank\" column and other columns\n",
    "    for i in range(max_length):\n",
    "        if extracted_data[\"last_name\"][i] is not None and extracted_data[\"first_name\"][i] is not None and extracted_data[\"rank\"][i] is None:\n",
    "            extracted_data[\"rank\"][i] = \"No Rank\"\n",
    "\n",
    "    # Remove all null values from all columns\n",
    "    for key, value_list in extracted_data.items():\n",
    "        extracted_data[key] = [value for value in value_list if value is not None]    \n",
    "\n",
    "    # Check if any page numbers are extracted\n",
    "    if extracted_data[\"page\"]:\n",
    "        page_number = extracted_data[\"page\"][0]\n",
    "    else:\n",
    "        page_number = \"Page Number Not Detected\"\n",
    "    \n",
    "    extracted_data[\"page\"] = [page_number] * len(extracted_data[\"last_name\"])\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bfd4cd5-09d8-422b-b717-e0597a42527a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_to_csv(extracted_data, output_file):\n",
    "    entities = list(extracted_data.keys())\n",
    "    max_length = max(len(extracted_data[entity]) for entity in entities)\n",
    "\n",
    "    # Pad shorter lists with None values to match the length of the longest list\n",
    "    for entity in entities:\n",
    "        extracted_data[entity] += [None] * (max_length - len(extracted_data[entity]))\n",
    "\n",
    "    # Filter out rows with null values\n",
    "    non_null_indices = [i for i in range(max_length) if all(extracted_data[key][i] is not None for key in extracted_data)]\n",
    "    extracted_data = {key: [extracted_data[key][i] for i in non_null_indices] for key in extracted_data}\n",
    "\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(entities)\n",
    "        for i in range(len(non_null_indices)):\n",
    "            row_data = [extracted_data[entity][i] for entity in entities]\n",
    "            writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f673eb6b-4f8a-47b6-bad0-b6ad82a96df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_process(project_id, location, processor_id, path, field_mask=None, processor_version_id=None):\n",
    "    if os.path.isfile(path):\n",
    "        # If the path is a file, process the single file directly\n",
    "        file_name, extension = os.path.splitext(os.path.basename(path))\n",
    "        mime_type = determine_mime_type(extension)\n",
    "        process_document_sample(project_id, location, processor_id, path, mime_type, field_mask, processor_version_id)\n",
    "    elif os.path.isdir(path):\n",
    "        # If the path is a directory, determine MIME types for all files in the directory and process them\n",
    "        mime_types = directory_mime_types(path)\n",
    "        for file_name, mime_type in mime_types.items():\n",
    "            file_path = os.path.join(path, file_name)\n",
    "            process_document_sample(project_id, location, processor_id, file_path, mime_type, field_mask, processor_version_id)\n",
    "    else:\n",
    "        print(f\"Invalid path: '{path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5db55178-d07e-453e-b32b-26c0b227963f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def directory_mime_types(path):\n",
    "    mime_types = {}\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_name, extension = os.path.splitext(filename)\n",
    "            mime_type = determine_mime_type(extension)\n",
    "            mime_types[filename] = mime_type\n",
    "    return mime_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be50c496-9721-41c3-b0e6-c5c669516f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_mime_type(file_extension):\n",
    "    # Determine MIME type based on file extension\n",
    "    mime_types_mapping = {\n",
    "        \".pdf\": \"application/pdf\",\n",
    "        \".gif\": \"image/gif\",\n",
    "        \".tiff\": \"image/tiff\",\n",
    "        \".tif\": \"image/tiff\",\n",
    "        \".jpg\": \"image/jpeg\",\n",
    "        \".jpeg\": \"image/jpeg\",\n",
    "        \".png\": \"image/png\",\n",
    "        \".bmp\": \"image/bmp\",\n",
    "        \".webp\": \"image/webp\"\n",
    "    }\n",
    "    return mime_types_mapping.get(file_extension.lower(), \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f61e33c-d2d0-481a-b3b2-3c592ad35ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_document_sample(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    "    field_mask: Optional[str] = None,\n",
    "    processor_version_id: Optional[str] = None,\n",
    ") -> None:\n",
    "    # Initialize Document AI client\n",
    "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "\n",
    "    if processor_version_id:\n",
    "        name = client.processor_version_path(project_id, location, processor_id, processor_version_id)\n",
    "    else:\n",
    "        name = client.processor_path(project_id, location, processor_id)\n",
    "    \n",
    "    all_extracted_data = {\"last_name\": [], \"first_name\": [], \"rank\": [], \"regiment\": [], \"page\": []}\n",
    "    \n",
    "    if mime_type == \"application/pdf\":\n",
    "        doc = aw.Document(file_path)\n",
    "        for page in range(0, doc.page_count):\n",
    "            page_file_path = f\"page_{page}.pdf\"\n",
    "            extractedPage = doc.extract_pages(page, 1)\n",
    "            extractedPage.save(page_file_path)\n",
    "        \n",
    "            # Process each page image using Document AI OCR\n",
    "            with open(page_file_path, \"rb\") as image:\n",
    "                image_content = image.read()\n",
    "\n",
    "            raw_document = documentai.RawDocument(content=image_content, mime_type=mime_type)\n",
    "\n",
    "            process_options = documentai.ProcessOptions()\n",
    "\n",
    "            request = documentai.ProcessRequest(\n",
    "                name=name,\n",
    "                raw_document=raw_document,\n",
    "                field_mask=field_mask,\n",
    "                process_options=process_options,\n",
    "            )\n",
    "\n",
    "            result = client.process_document(request=request)\n",
    "            document = result.document\n",
    "\n",
    "            # Convert the OCR result to JSON for the current page\n",
    "            extracted_data = data_extraction(document)\n",
    "\n",
    "            for key, value_list in extracted_data.items():\n",
    "                all_extracted_data[key].extend(value_list)\n",
    "\n",
    "            os.remove(page_file_path)\n",
    "    \n",
    "    else:\n",
    "        # Process each page image using Document AI OCR\n",
    "            with open(file_path, \"rb\") as image:\n",
    "                image_content = image.read()\n",
    "\n",
    "            raw_document = documentai.RawDocument(content=image_content, mime_type=mime_type)\n",
    "\n",
    "            process_options = documentai.ProcessOptions()\n",
    "\n",
    "            request = documentai.ProcessRequest(\n",
    "                name=name,\n",
    "                raw_document=raw_document,\n",
    "                field_mask=field_mask,\n",
    "                process_options=process_options,\n",
    "            )\n",
    "\n",
    "            result = client.process_document(request=request)\n",
    "            document = result.document\n",
    "\n",
    "            # Convert the OCR result to JSON for the current page\n",
    "            extracted_data = data_extraction(document)\n",
    "\n",
    "            for key, value_list in extracted_data.items():\n",
    "                all_extracted_data[key].extend(value_list)\n",
    "    \n",
    "    # Save all extracted data to a single CSV file\n",
    "    output_file = os.path.splitext(os.path.basename(file_path))[0] + \"_extracted_data.csv\"\n",
    "    save_to_csv(all_extracted_data, output_file)\n",
    "    print(f\"All extracted data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "feb0725d-a47b-412e-8c72-de3516449849",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All extracted data saved to test_extracted_data.csv\n",
      "All extracted data saved to 00000024_extracted_data.csv\n"
     ]
    }
   ],
   "source": [
    "determine_process(\n",
    "    project_id=\"322996871040\",\n",
    "    location=\"us\",\n",
    "    processor_id=\"eb7f025d9a48d15\",\n",
    "    path=\"test\",  \n",
    "    #processor_version_id=\"69f0b6febc1d5673\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bad7e3-727d-429d-861f-a7debbb3e59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
